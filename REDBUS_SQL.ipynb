{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f575c-fbb3-46d6-be9f-7e3fc89238d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Establish the connection to MySQL\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",  # Specify the host, commonly localhost\n",
    "    user=\"root\",       # Your MySQL username\n",
    "    password=\"SHYAM@sk25\"  # Your MySQL password\n",
    ")\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "# Create the database 'REDBUS' if it doesn't exist\n",
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS REDBUS\")\n",
    "print(\"Database 'REDBUS' created (or already exists)\")\n",
    "\n",
    "# Use the 'REDBUS' database\n",
    "cursor.execute(\"USE REDBUS\")\n",
    "\n",
    "# Define the schema for the MySQL table\n",
    "schema = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bus_routes (\n",
    "    id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    route_name TEXT,\n",
    "    route_link TEXT,\n",
    "    busname TEXT,\n",
    "    bustype TEXT,\n",
    "    departing_time TIME,\n",
    "    duration TEXT,\n",
    "    reaching_time TIME,\n",
    "    price DECIMAL(10,2),\n",
    "    seats_available INT,\n",
    "    star_rating FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(schema)\n",
    "print(\"Table 'bus_routes' created successfully!\")\n",
    "\n",
    "# List of CSV files to read\n",
    "csv_files = [\n",
    "    'himachal_bus_details.csv', 'south_bengal_bus_details.csv', 'uttar_pradesh_bus_details.csv',\n",
    "    'andhra_pradesh_bus_details.csv', 'WEST_BENGAL_bus_details.csv', 'Telangana_bus_details.csv',\n",
    "    'rajasthan_bus_details.csv', 'kerala_bus_details.csv', 'chandigarh_bus_details.csv', 'punjab_bus_details.csv'\n",
    "]\n",
    "\n",
    "# Combine data from all CSV files into a single DataFrame\n",
    "dfs = [pd.read_csv(file) for file in csv_files]\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rename columns to lowercase and match the database schema\n",
    "combined_df.columns = combined_df.columns.str.lower()  # Normalize column names to lowercase\n",
    "\n",
    "# Debug: Print column names to verify they match the schema\n",
    "print(\"Columns in DataFrame after normalization:\", combined_df.columns)\n",
    "\n",
    "# Rename columns to match the database table schema\n",
    "combined_df.rename(columns={\n",
    "    \"departing_time\": \"departing_time\",\n",
    "    \"reaching_time\": \"reaching_time\",\n",
    "    \"star_rating\": \"star_rating\",\n",
    "    \"seat_availability\": \"seats_available\",\n",
    "    \"route_name\": \"route_name\",\n",
    "    \"route_link\": \"route_link\",\n",
    "    \"bus_name\": \"busname\",\n",
    "    \"bus_type\": \"bustype\",\n",
    "    \"price\": \"price\",\n",
    "    \"duration\": \"duration\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Clean and transform data\n",
    "\n",
    "# Convert time columns to proper MySQL TIME format\n",
    "for time_col in ['departing_time', 'reaching_time']:\n",
    "    if time_col in combined_df.columns:\n",
    "        combined_df[time_col] = pd.to_datetime(combined_df[time_col], format='%H:%M', errors='coerce').dt.time\n",
    "\n",
    "# Clean the 'price' column\n",
    "if 'price' in combined_df.columns:\n",
    "    combined_df['price'] = (\n",
    "        combined_df['price'].astype(str)\n",
    "        .str.replace('INR ', '', regex=False)\n",
    "        .str.replace(',', '', regex=False)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# Extract seat numbers from the 'seats_available' column\n",
    "if 'seats_available' in combined_df.columns:\n",
    "    combined_df['seats_available'] = (\n",
    "        combined_df['seats_available']\n",
    "        .astype(str)\n",
    "        .str.extract(r'(\\d+)')\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "# Drop rows with missing critical data\n",
    "critical_columns = ['route_name', 'route_link', 'busname', 'bustype', 'departing_time', 'reaching_time', 'price', 'seats_available', 'star_rating']\n",
    "combined_df = combined_df.dropna(subset=critical_columns)\n",
    "\n",
    "# Debug: Check the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame preview:\")\n",
    "print(combined_df.head())\n",
    "\n",
    "# Prepare data for insertion\n",
    "columns_to_insert = [\n",
    "    \"route_name\", \"route_link\", \"busname\", \"bustype\",\n",
    "    \"departing_time\", \"duration\", \"reaching_time\",\n",
    "    \"price\", \"seats_available\", \"star_rating\"\n",
    "]\n",
    "insert_query = f\"\"\"\n",
    "    INSERT INTO bus_routes ({', '.join(columns_to_insert)}) \n",
    "    VALUES ({', '.join(['%s'] * len(columns_to_insert))})\n",
    "\"\"\"\n",
    "data = combined_df[columns_to_insert].values.tolist()\n",
    "\n",
    "# Insert data into the 'bus_routes' table\n",
    "cursor.executemany(insert_query, data)\n",
    "mydb.commit()\n",
    "print(f\"Data inserted into table 'bus_routes' successfully!\")\n",
    "\n",
    "# Close the database connection\n",
    "cursor.close()\n",
    "mydb.close()\n",
    "\n",
    "# Display the final DataFrame to verify\n",
    "print(\"Final DataFrame:\")\n",
    "print(combined_df)\n",
    "\n",
    "# Establish the connection to MySQL\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",  # Specify the host, commonly localhost\n",
    "    user=\"root\",       # Your MySQL username\n",
    "    password=\"SHYAM@sk25\"  # Your MySQL password\n",
    ")\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "# Create the database 'REDBUS' if it doesn't exist\n",
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS REDBUS\")\n",
    "print(\"Database 'REDBUS' created (or already exists)\")\n",
    "\n",
    "# Use the 'REDBUS' database\n",
    "cursor.execute(\"USE REDBUS\")\n",
    "\n",
    "# Define the schema for the MySQL table\n",
    "schema = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bus_routes (\n",
    "    id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    route_name TEXT,\n",
    "    route_link TEXT,\n",
    "    busname TEXT,\n",
    "    bustype TEXT,\n",
    "    departing_time TIME,\n",
    "    duration TEXT,\n",
    "    reaching_time TIME,\n",
    "    price DECIMAL(10,2),\n",
    "    seats_available INT,\n",
    "    star_rating FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(schema)\n",
    "print(\"Table 'bus_routes' created successfully!\")\n",
    "\n",
    "# List of CSV files to read\n",
    "csv_files = [\n",
    "    'himachal_bus_details.csv', 'south_bengal_bus_details.csv', 'uttar_pradesh_bus_details.csv',\n",
    "    'andhra_pradesh_bus_details.csv', 'WEST_BENGAL_bus_details.csv', 'Telangana_bus_details.csv',\n",
    "    'rajasthan_bus_details.csv', 'kerala_bus_details.csv', 'chandigarh_bus_details.csv', 'punjab_bus_details.csv'\n",
    "]\n",
    "\n",
    "# Combine data from all CSV files into a single DataFrame\n",
    "dfs = [pd.read_csv(file) for file in csv_files]\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rename columns to lowercase and match the database schema\n",
    "combined_df.columns = combined_df.columns.str.lower()  # Normalize column names to lowercase\n",
    "\n",
    "# Debug: Print column names to verify they match the schema\n",
    "print(\"Columns in DataFrame after normalization:\", combined_df.columns)\n",
    "\n",
    "# Rename columns to match the database table schema\n",
    "combined_df.rename(columns={\n",
    "    \"departing_time\": \"departing_time\",\n",
    "    \"reaching_time\": \"reaching_time\",\n",
    "    \"star_rating\": \"star_rating\",\n",
    "    \"seat_availability\": \"seats_available\",\n",
    "    \"route_name\": \"route_name\",\n",
    "    \"route_link\": \"route_link\",\n",
    "    \"bus_name\": \"busname\",\n",
    "    \"bus_type\": \"bustype\",\n",
    "    \"price\": \"price\",\n",
    "    \"duration\": \"duration\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Clean and transform data\n",
    "\n",
    "# Convert time columns to proper MySQL TIME format\n",
    "for time_col in ['departing_time', 'reaching_time']:\n",
    "    if time_col in combined_df.columns:\n",
    "        combined_df[time_col] = pd.to_datetime(combined_df[time_col], format='%H:%M', errors='coerce').dt.time\n",
    "\n",
    "# Clean the 'price' column\n",
    "if 'price' in combined_df.columns:\n",
    "    combined_df['price'] = (\n",
    "        combined_df['price'].astype(str)\n",
    "        .str.replace('INR ', '', regex=False)\n",
    "        .str.replace(',', '', regex=False)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# Extract seat numbers from the 'seats_available' column\n",
    "if 'seats_available' in combined_df.columns:\n",
    "    combined_df['seats_available'] = (\n",
    "        combined_df['seats_available']\n",
    "        .astype(str)\n",
    "        .str.extract(r'(\\d+)')\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "# Drop rows with missing critical data\n",
    "critical_columns = ['route_name', 'route_link', 'busname', 'bustype', 'departing_time', 'reaching_time', 'price', 'seats_available', 'star_rating']\n",
    "combined_df = combined_df.dropna(subset=critical_columns)\n",
    "\n",
    "# Debug: Check the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame preview:\")\n",
    "print(combined_df.head())\n",
    "\n",
    "# Prepare data for insertion\n",
    "columns_to_insert = [\n",
    "    \"route_name\", \"route_link\", \"busname\", \"bustype\",\n",
    "    \"departing_time\", \"duration\", \"reaching_time\",\n",
    "    \"price\", \"seats_available\", \"star_rating\"\n",
    "]\n",
    "insert_query = f\"\"\"\n",
    "    INSERT INTO bus_routes ({', '.join(columns_to_insert)}) \n",
    "    VALUES ({', '.join(['%s'] * len(columns_to_insert))})\n",
    "\"\"\"\n",
    "data = combined_df[columns_to_insert].values.tolist()\n",
    "\n",
    "# Insert data into the 'bus_routes' table\n",
    "cursor.executemany(insert_query, data)\n",
    "mydb.commit()\n",
    "print(f\"Data inserted into table 'bus_routes' successfully!\")\n",
    "\n",
    "# Close the database connection\n",
    "cursor.close()\n",
    "mydb.close()\n",
    "\n",
    "# Display the final DataFrame to verify\n",
    "print(\"Final DataFrame:\")\n",
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1d0d6-fc13-4ceb-b6f8-505bb2042499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e60bd-901a-4a1b-810c-cd296826911a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c72a0-687e-433a-9fdd-0d5d45bbf7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f480e-4beb-4637-bf9b-a45a79d238ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
