{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b8549a-3181-46a8-957a-bc963bfdde34",
   "metadata": {},
   "source": [
    "Redbus Data Scraping with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed703b-9867-4a04-bbd3-be324c825366",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium\n",
    "Downloads\\PYTHON\\RED BUS\\Untitled Folder\\streamlit_bus_filter_app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768a61ce-b9ac-491a-82e1-b37c4c345c01",
   "metadata": {},
   "source": [
    "1.Government State Bus Transport: PUNJAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c008f6-aa0e-4aef-91bd-dab90f4d9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PEPSU (Punjab) Bus Routes & Timings \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/pepsu/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\"\n",
    "    Initializes and returns a Chrome WebDriver instance.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    \"\"\"\n",
    "    Loads the specified URL and waits for the page to load.\n",
    "    \"\"\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"route\"))\n",
    "    )  # Wait until the routes are loaded\n",
    "    time.sleep(2)  # Allow time for the page to load completely\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    \"\"\"\n",
    "    Scrapes the bus route links and names from the initial page.\n",
    "    \"\"\"\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    \"\"\"\n",
    "    Scrapes bus details from a specific route page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"button\"))\n",
    "        )  # Wait until the \"View Buses\" button is visible\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Try to click the \"View Buses\" button if available\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            time.sleep(5)  # Allow buses to load\n",
    "\n",
    "            # Scroll down to load more content if needed\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for additional content to load\n",
    "\n",
    "            # Collect bus details from the page\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to capture seat availability (different classes for different sections)\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    \"\"\"\n",
    "    Scrapes all pages of bus routes and details.\n",
    "    \"\"\"\n",
    "    all_bus_details = []\n",
    "    \n",
    "    # Initialize WebDriver\n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    try:\n",
    "        for page in range(1, 4):  # Scraping 3 pages of bus routes\n",
    "            try:\n",
    "                load_page(driver, URL)\n",
    "\n",
    "                if page > 1:\n",
    "                    # Adjust for page navigation\n",
    "                    pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, f\"//div[@class='DC_117_pageTabs '][text()='{page}']\"))\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                    driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                    time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "                # Scrape bus routes on the current page\n",
    "                all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "\n",
    "                # Iterate through each route and scrape bus details\n",
    "                for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                    bus_details = scrape_bus_details(driver, link, name)\n",
    "                    if bus_details:\n",
    "                        all_bus_details.extend(bus_details)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "    finally:\n",
    "        # Ensure the driver is properly quit even if an error occurs\n",
    "        driver.quit()\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "# Start the scraping process\n",
    "all_bus_details = scrape_all_pages()\n",
    "\n",
    "# Convert the list of bus details to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('punjab_bus_details.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed and data saved to 'punjab_bus_details.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf25a4-f161-4992-a98c-a4a66f076287",
   "metadata": {},
   "source": [
    "2.Government State Bus Transport: CHANDIGARH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca18fa6-6765-4bb6-8490-7bea4880df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chandigarh Transport Undertaking (CTU) Bus Routes & Timings \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL for Chandigarh Transport Undertaking (CTU) buses\n",
    "URL = \"https://www.redbus.in/online-booking/chandigarh-transport-undertaking-ctu\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"route\")))\n",
    "    time.sleep(2)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"button\")))\n",
    "        time.sleep(3)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, \"button\")))\n",
    "            view_buses_button.click()\n",
    "            time.sleep(5)\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)\n",
    "\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    try:\n",
    "        for page in range(1, 4):\n",
    "            try:\n",
    "                load_page(driver, URL)\n",
    "\n",
    "                if page > 1:\n",
    "                    pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                    driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                    time.sleep(5)\n",
    "\n",
    "                all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "\n",
    "                for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                    bus_details = scrape_bus_details(driver, link, name)\n",
    "                    if bus_details:\n",
    "                        all_bus_details.extend(bus_details)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error on page {page}: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "all_bus_details = scrape_all_pages()\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "df.to_csv('chandigarh_bus_details.csv', index=False)\n",
    "print(\"Data saved to 'chandigarh_bus_details.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2d791b-62c4-43a0-a137-b21b582585e9",
   "metadata": {},
   "source": [
    "3.Government State Bus Transport: KERALA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03084a1-8505-4079-ba0b-265249e7f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KSRTC (Kerala) Bus Routes & Timings\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website for Kerala KSRTC\n",
    "URL = \"https://www.redbus.in/online-booking/ksrtc-kerala/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\"\n",
    "    Initializes and returns a Chrome WebDriver instance.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    \"\"\"\n",
    "    Loads the specified URL and waits for the page to load.\n",
    "    \"\"\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"route\"))\n",
    "    )  # Wait until the routes are loaded\n",
    "    time.sleep(2)  # Allow time for page to load completely\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    \"\"\"\n",
    "    Scrapes the bus route links and names from the initial page.\n",
    "    \"\"\"\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    \"\"\"\n",
    "    Scrapes bus details from a specific route page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"button\"))\n",
    "        )  # Wait until the \"View Buses\" button is visible\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Try to click the \"View Buses\" button if available\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            time.sleep(5)  # Allow buses to load\n",
    "\n",
    "            # Scroll down to load more content if needed\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for additional content to load\n",
    "\n",
    "            # Collect bus details from the page\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to capture seat availability (different classes for different sections)\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    \"\"\"\n",
    "    Scrapes all pages of bus routes and details.\n",
    "    \"\"\"\n",
    "    all_bus_details = []\n",
    "    \n",
    "    # Initialize WebDriver\n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    try:\n",
    "        for page in range(1, 3):  # Scraping 2 pages of bus routes\n",
    "            try:\n",
    "                load_page(driver, URL)\n",
    "\n",
    "                if page > 1:\n",
    "                    # Updated pagination based on the page number HTML provided\n",
    "                    pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page}']\"))\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                    driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                    time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "                # Scrape bus routes on the current page\n",
    "                all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "\n",
    "                # Iterate through each route and scrape bus details\n",
    "                for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                    bus_details = scrape_bus_details(driver, link, name)\n",
    "                    if bus_details:\n",
    "                        all_bus_details.extend(bus_details)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "    finally:\n",
    "        # Ensure the driver is properly quit even if an error occurs\n",
    "        driver.quit()\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "# Start the scraping process\n",
    "all_bus_details = scrape_all_pages()\n",
    "\n",
    "# Convert the list of bus details to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('kerala_bus_details.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed and data saved to 'kerala_bus_details.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2736006-0ee2-476b-bef5-fe485009c023",
   "metadata": {},
   "source": [
    "4.Government State Bus Transport:RAJASTHAN   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9cdff-7ea7-404c-ba3c-41fdcaba6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KSRTC (Kerala) Bus Routes & Timings\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/rsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\"\n",
    "    Initializes and returns a Chrome WebDriver instance.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    \"\"\"\n",
    "    Loads the specified URL and waits for the page to load.\n",
    "    \"\"\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"route\"))\n",
    "    )  # Wait until the routes are loaded\n",
    "    time.sleep(2)  # Allow time for page to load completely\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    \"\"\"\n",
    "    Scrapes the bus route links and names from the initial page.\n",
    "    \"\"\"\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    \"\"\"\n",
    "    Scrapes bus details from a specific route page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"button\"))\n",
    "        )  # Wait until the \"View Buses\" button is visible\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Try to click the \"View Buses\" button if available\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            time.sleep(5)  # Allow buses to load\n",
    "\n",
    "            # Scroll down to load more content if needed\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for additional content to load\n",
    "\n",
    "            # Collect bus details from the page\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to capture seat availability (different classes for different sections)\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    \"\"\"\n",
    "    Scrapes all pages of bus routes and details.\n",
    "    \"\"\"\n",
    "    all_bus_details = []\n",
    "    \n",
    "    # Initialize WebDriver\n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    try:\n",
    "        for page in range(1, 3):  # Scraping 2 pages of bus routes\n",
    "            try:\n",
    "                load_page(driver, URL)\n",
    "\n",
    "                if page > 1:\n",
    "                    pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                    driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                    time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "                # Scrape bus routes on the current page\n",
    "                all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "\n",
    "                # Iterate through each route and scrape bus details\n",
    "                for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                    bus_details = scrape_bus_details(driver, link, name)\n",
    "                    if bus_details:\n",
    "                        all_bus_details.extend(bus_details)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "    finally:\n",
    "        # Ensure the driver is properly quit even if an error occurs\n",
    "        driver.quit()\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "# Start the scraping process\n",
    "all_bus_details = scrape_all_pages()\n",
    "\n",
    "# Convert the list of bus details to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('rajasthan_bus_details.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed and data saved to 'rajasthan_bus_details.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4734f5fb-510f-4bb6-a860-8a8d3c901d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "150a1c78-0f76-4424-a98f-f91fa5fc5750",
   "metadata": {},
   "source": [
    "5.Government State Bus Transport: TELANGANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11cfae2-6f9d-4f97-8515-a65ed6f46a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TGSRTC Bus Routes & Timings\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/tsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\"Initialize and return a Chrome WebDriver instance.\"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    \"\"\"Load the given URL and wait for the page to load.\"\"\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "    time.sleep(random.uniform(2, 5))  # Random sleep time to simulate human interaction\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    \"\"\"Scrape bus routes (links and names) from the main page.\"\"\"\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    \"\"\"Scrape detailed information about buses for a given route.\"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"button\")))\n",
    "\n",
    "        # Click the \"View Buses\" button if available\n",
    "        view_buses_button = driver.find_element(By.CLASS_NAME, \"button\")\n",
    "        driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "\n",
    "        # Scroll to the bottom to load all bus items\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "\n",
    "        # Extract bus details\n",
    "        bus_details = []\n",
    "        bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels\")\n",
    "        bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type\")\n",
    "        departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time\")\n",
    "        duration_elements = driver.find_elements(By.CLASS_NAME, \"dur\")\n",
    "        reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CLASS_NAME, \"fare\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30')]\")\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": route_name,\n",
    "                \"Route_Link\": url,\n",
    "                \"Bus_Name\": bus_name_elements[i].text,\n",
    "                \"Bus_Type\": bus_type_elements[i].text,\n",
    "                \"Departing_Time\": departing_time_elements[i].text,\n",
    "                \"Duration\": duration_elements[i].text,\n",
    "                \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                \"Price\": price_elements[i].text,\n",
    "                \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    \"\"\"Scrape bus routes and details across multiple pages.\"\"\"\n",
    "    all_bus_details = []\n",
    "    driver = initialize_driver()\n",
    "\n",
    "    try:\n",
    "        load_page(driver, URL)\n",
    "\n",
    "        # Scrape bus route links and names\n",
    "        all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "\n",
    "        for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "            bus_details = scrape_bus_details(driver, link, name)\n",
    "            if bus_details:\n",
    "                all_bus_details.extend(bus_details)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "all_bus_details = scrape_all_pages()\n",
    "\n",
    "# Convert the list of bus details into a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('Telangana_bus_details.csv', index=False)\n",
    "\n",
    "print(\"Bus details have been successfully saved to 'Telangana_bus_details.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846cdac2-5bf2-4814-8324-6e7d21308c46",
   "metadata": {},
   "source": [
    "6.Government State Bus Transport: WEST BENGAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97783c-8896-404c-80ae-75d383a114b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#West bengal transport corporation Bus Routes & Timings\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/west-bengal-transport-corporation?utm_source=rtchometile\"\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(URL)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Allow the page to load fully (wait 10 seconds to ensure all elements are loaded)\n",
    "time.sleep(10)\n",
    "print(f\"Page successfully loaded: {URL}\")\n",
    "\n",
    "def scrape_bus_routes():\n",
    "    \"\"\"Scrape the list of bus routes from the main page.\"\"\"\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Scrape the main page for route links and names\n",
    "all_bus_routes_link, all_bus_routes_name = scrape_bus_routes()\n",
    "\n",
    "def scrape_bus_details(url, route_name):\n",
    "    \"\"\"Scrape detailed information for each bus route.\"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Scroll down to load all bus items (wait for a few seconds)\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(3)  # Wait for more content to load\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        # Find the details for each bus\n",
    "        bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels\")\n",
    "        bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type\")\n",
    "        departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time\")\n",
    "        duration_elements = driver.find_elements(By.CLASS_NAME, \"dur\")\n",
    "        reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CLASS_NAME, \"fare\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "        # Collect bus details\n",
    "        bus_details = []\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            bus_detail = {\n",
    "                \"Route_Name\": route_name,\n",
    "                \"Route_Link\": url,\n",
    "                \"Bus_Name\": bus_name_elements[i].text,\n",
    "                \"Bus_Type\": bus_type_elements[i].text,\n",
    "                \"Departing_Time\": departing_time_elements[i].text,\n",
    "                \"Duration\": duration_elements[i].text,\n",
    "                \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                \"Price\": price_elements[i].text,\n",
    "                \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while processing route: {url}. Error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Scrape bus details for each route\n",
    "for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "    bus_details = scrape_bus_details(link, name)\n",
    "    if bus_details:\n",
    "        all_bus_details.extend(bus_details)\n",
    "\n",
    "# Convert the list of bus details into a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('WEST_BENGAL_bus_details.csv', index=False)\n",
    "print(\"Bus details have been successfully saved to 'WEST_BENGAL_bus_details.csv'.\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87e837-21c4-4541-8c73-a3694e47f81d",
   "metadata": {},
   "source": [
    "7.Government State Bus Transport: ANDHRA PRADESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d983c-98b0-4f12-b44d-29a14f29e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APSRTC Bus Routes & Timings\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the APSRTC page\n",
    "URL = \"https://www.redbus.in/online-booking/apsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\"\n",
    "    Initializes and returns a Chrome WebDriver instance.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    \"\"\"\n",
    "    Loads the specified URL and waits for the page to load.\n",
    "    \"\"\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"route\"))\n",
    "    )  # Wait until the routes are loaded\n",
    "    time.sleep(2)  # Allow time for page to load completely\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    \"\"\"\n",
    "    Scrapes the bus route links and names from the initial page.\n",
    "    \"\"\"\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    \"\"\"\n",
    "    Scrapes bus details from a specific route page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"button\"))\n",
    "        )  # Wait until the \"View Buses\" button is visible\n",
    "        time.sleep(3)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            time.sleep(5)\n",
    "\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)\n",
    "\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    \"\"\"\n",
    "    Scrapes all pages of bus routes and details.\n",
    "    \"\"\"\n",
    "    all_bus_details = []\n",
    "\n",
    "    driver = initialize_driver()\n",
    "    try:\n",
    "        for page in range(1, 6):  # Scraping up to 5 pages of routes based on your input\n",
    "            try:\n",
    "                load_page(driver, URL)\n",
    "\n",
    "                if page > 1:\n",
    "                    # Locate the pagination tab using the class provided\n",
    "                    pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, f\"//div[@class='DC_117_pageTabs '][text()='{page}']\"))\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                    driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                    time.sleep(5)\n",
    "\n",
    "                all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "\n",
    "                for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                    bus_details = scrape_bus_details(driver, link, name)\n",
    "                    if bus_details:\n",
    "                        all_bus_details.extend(bus_details)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "# Start the scraping process\n",
    "all_bus_details = scrape_all_pages()\n",
    "\n",
    "# Convert the list of bus details to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('andhra_pradesh_bus_details.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed and data saved to 'andhra_pradesh_bus_details.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134be697-a038-483b-acc2-3e55672a7747",
   "metadata": {},
   "source": [
    "8.Government State Bus Transport: UTTAR PRADESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff0573b-b025-4eac-ad12-4b5ca80f98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPSRTC Bus Routes & Timings  \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the UPSRTC website\n",
    "URL = \"https://www.redbus.in/online-booking/uttar-pradesh-state-road-transport-corporation-upsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\"\n",
    "    Initializes and returns a Chrome WebDriver instance.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    \"\"\"\n",
    "    Loads the specified URL and waits for the page to load.\n",
    "    \"\"\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"route\"))\n",
    "    )  # Wait until the routes are loaded\n",
    "    time.sleep(2)  # Allow time for page to load completely\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    \"\"\"\n",
    "    Scrapes the bus route links and names from the initial page.\n",
    "    \"\"\"\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    \"\"\"\n",
    "    Scrapes bus details from a specific route page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"button\"))\n",
    "        )  # Wait until the \"View Buses\" button is visible\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Try to click the \"View Buses\" button if available\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            time.sleep(5)  # Allow buses to load\n",
    "\n",
    "            # Scroll down to load more content if needed\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for additional content to load\n",
    "\n",
    "            # Collect bus details from the page\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to capture seat availability (different classes for different sections)\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    \"\"\"\n",
    "    Scrapes all pages of bus routes and details.\n",
    "    \"\"\"\n",
    "    all_bus_details = []\n",
    "    \n",
    "    # Initialize WebDriver\n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    try:\n",
    "        for page in range(1, 6):  # Scraping 5 pages of bus routes\n",
    "            try:\n",
    "                load_page(driver, URL)\n",
    "\n",
    "                if page > 1:\n",
    "                    pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                    driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                    time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "                # Scrape bus routes on the current page\n",
    "                all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "\n",
    "                # Iterate through each route and scrape bus details\n",
    "                for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                    bus_details = scrape_bus_details(driver, link, name)\n",
    "                    if bus_details:\n",
    "                        all_bus_details.extend(bus_details)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "    finally:\n",
    "        # Ensure the driver is properly quit even if an error occurs\n",
    "        driver.quit()\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "# Start the scraping process\n",
    "all_bus_details = scrape_all_pages()\n",
    "\n",
    "# Convert the list of bus details to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('uttar_pradesh_bus_details.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed and data saved to 'uttar_pradesh_bus_details.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d8485-5875-498b-825d-3cf5c7251ee6",
   "metadata": {},
   "source": [
    "9.Government State Bus Transport: SOUTH BENGAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a14be0-1ecc-47fd-9b92-e50501b175e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#South Bengal State Transport Corporation (SBSTC) Bus Routes & Timings\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "\n",
    "# URL for South Bengal State Transport Corporation (SBSTC)\n",
    "URL = \"https://www.redbus.in/online-booking/south-bengal-state-transport-corporation-sbstc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\"\n",
    "    Initializes and returns a Chrome WebDriver instance.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url, retries=3):\n",
    "    \"\"\"\n",
    "    Loads the specified URL and waits for the page to load with retry mechanism.\n",
    "    \"\"\"\n",
    "    attempts = 0\n",
    "    while attempts < retries:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"route\"))\n",
    "            )  # Wait until the routes are loaded\n",
    "            time.sleep(2)  # Allow time for page to load completely\n",
    "            break\n",
    "        except (TimeoutException, WebDriverException) as e:\n",
    "            print(f\"Error loading page, retrying... (Attempt {attempts + 1}/{retries})\")\n",
    "            attempts += 1\n",
    "            if attempts == retries:\n",
    "                raise Exception(f\"Failed to load page {url} after {retries} attempts.\")\n",
    "            time.sleep(3)  # Wait a bit before retrying\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    \"\"\"\n",
    "    Scrapes the bus route links and names from the initial page.\n",
    "    \"\"\"\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    \"\"\"\n",
    "    Scrapes bus details from a specific route page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"button\"))\n",
    "        )  # Wait until the \"View Buses\" button is visible\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Try to click the \"View Buses\" button if available\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            time.sleep(5)  # Allow buses to load\n",
    "\n",
    "            # Scroll down to load more content if needed\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for additional content to load\n",
    "\n",
    "            # Collect bus details from the page\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to capture seat availability (different classes for different sections)\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    \"\"\"\n",
    "    Scrapes all pages of bus routes and details.\n",
    "    \"\"\"\n",
    "    all_bus_details = []\n",
    "    \n",
    "    # Initialize WebDriver\n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    try:\n",
    "        for page in range(1, 3):  # Scraping 2 pages of bus routes\n",
    "            try:\n",
    "                load_page(driver, URL)\n",
    "\n",
    "                if page > 1:\n",
    "                    pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                    driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                    time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "                # Scrape bus routes on the current page\n",
    "                all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "\n",
    "                # Iterate through each route and scrape bus details\n",
    "                for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                    bus_details = scrape_bus_details(driver, link, name)\n",
    "                    if bus_details:\n",
    "                        all_bus_details.extend(bus_details)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "    finally:\n",
    "        # Ensure the driver is properly quit even if an error occurs\n",
    "        driver.quit()\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "# Start the scraping process\n",
    "all_bus_details = scrape_all_pages()\n",
    "\n",
    "# Convert the list of bus details to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('south_bengal_bus_details.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed and data saved to 'south_bengal_bus_details.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21723cb2-170a-4930-a265-0f31210e2ee3",
   "metadata": {},
   "source": [
    "10.Government State Bus Transport: Himachal Pradesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06061da6-ae55-4d44-86cc-5e0811011976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HRTC Bus Routes & Timings \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the HRTC (Himachal Pradesh) page\n",
    "URL = \"https://www.redbus.in/online-booking/hrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\"\n",
    "    Initializes and returns a Chrome WebDriver instance.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    \"\"\"\n",
    "    Loads the specified URL and waits for the page to load.\n",
    "    \"\"\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"route\"))\n",
    "    )  # Wait until the routes are loaded\n",
    "    time.sleep(2)  # Allow time for page to load completely\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    \"\"\"\n",
    "    Scrapes the bus route links and names from the initial page.\n",
    "    \"\"\"\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    \"\"\"\n",
    "    Scrapes bus details from a specific route page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"button\"))\n",
    "        )  # Wait until the \"View Buses\" button is visible\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Try to click the \"View Buses\" button if available\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            view_buses_button.click()\n",
    "            time.sleep(5)  # Allow buses to load\n",
    "\n",
    "            # Scroll down to load more content if needed\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for additional content to load\n",
    "\n",
    "            # Collect bus details from the page\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to capture seat availability (different classes for different sections)\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    \"\"\"\n",
    "    Scrapes all pages of bus routes and details.\n",
    "    \"\"\"\n",
    "    all_bus_details = []\n",
    "    \n",
    "    # Initialize WebDriver\n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    try:\n",
    "        for page in range(1, 5):  # Scraping 4 pages of bus routes\n",
    "            try:\n",
    "                load_page(driver, URL)\n",
    "\n",
    "                if page > 1:\n",
    "                    pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                    driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                    time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "                # Scrape bus routes on the current page\n",
    "                all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "\n",
    "                # Iterate through each route and scrape bus details\n",
    "                for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                    bus_details = scrape_bus_details(driver, link, name)\n",
    "                    if bus_details:\n",
    "                        all_bus_details.extend(bus_details)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "    finally:\n",
    "        # Ensure the driver is properly quit even if an error occurs\n",
    "        driver.quit()\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "# Start the scraping process\n",
    "all_bus_details = scrape_all_pages()\n",
    "\n",
    "# Convert the list of bus details to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('himachal_bus_details.csv', index=False)\n",
    "\n",
    "print(\"Scraping completed and data saved to 'himachal_bus_details.csv'.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea76489-9b77-404f-8513-1c9de1cea64b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
